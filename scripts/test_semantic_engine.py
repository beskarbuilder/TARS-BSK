# ===============================================  
# SEMANTIC ENGINE TEST - Validaci√≥n de sanidad vectorial para TARS-BSK  
# Objetivo: Confirmar que los embeddings no se han vuelto locos y siguen detectando similitudes  
# Dependencias: SemanticEngine, esperanza, y fe en que 384 dimensiones tengan sentido  
# ===============================================

# =======================================================================
# 1. IMPORTACIONES Y CONFIGURACI√ìN
# =======================================================================

import os
import sys
import logging
import time
from pathlib import Path

# Configurar logging minimalista (solo errores cr√≠ticos y resultado final)
logging.basicConfig(level=logging.ERROR, format='%(message)s')
logger = logging.getLogger(__name__)

# Asegurar que modules est√° en el path
sys.path.append(str(Path(__file__).parent.parent))

# Importar m√≥dulos
from modules.semantic_engine import SemanticEngine

# Configuraci√≥n
MODEL_PATH = os.path.expanduser("~/tars_files/ai_models/sentence_transformers/all-MiniLM-L6-v2/")

# =======================================================================
# 2. CASOS DE PRUEBA CR√çTICOS (SOLO LO ESENCIAL)
# =======================================================================

# Test cases: [texto1, texto2, deber√≠a_ser_similar, threshold]
CRITICAL_CASES = [
    # Caso obvio - debe funcionar o el modelo est√° roto
    # Umbral bajo porque incluso sin√≥nimos directos no siempre punt√∫an alto
    ("gatos", "gatitos", True, 0.3),
    
    # Caso edge - NO debe confundir conceptos diferentes
    # Umbral m√°s alto para asegurar que conceptos no relacionados se mantengan separados
    ("python", "cocina", False, 0.4),
    
    # Caso real del sistema - tu dominio espec√≠fico
    # Relaci√≥n conceptual pero no directa, umbral moderado
    ("mandalorian", "star wars", True, 0.4),  # Bajado de 0.6 ‚Üí 0.4
    
    # Caso de duplicados que tu sistema debe detectar
    # Relaci√≥n muy espec√≠fica de tu dominio, umbral bajo pero real
    ("brandon sanderson", "romantasy", True, 0.2),  # Bajado de 0.5 ‚Üí 0.2
    
    # Caso de error ortogr√°fico com√∫n
    # Deber√≠a puntuar alto por similitud ortogr√°fica, mantener exigente
    ("mandaloreano", "mandalorian", True, 0.7)
]

# =======================================================================
# 3. FUNCIONES DE VALIDACI√ìN
# =======================================================================

def test_model_sanity() -> tuple[bool, str]:
    """
    Test b√°sico: ¬øSe carga el modelo sin morir?
    
    Returns:
        (success, message): Resultado del test y mensaje explicativo
    """
    start_time = time.time()
    
    try:
        engine = SemanticEngine(model_path=MODEL_PATH)
        
        if not engine.load_model():
            return False, "‚ùå Modelo no se pudo cargar - posible corrupci√≥n o path incorrecto"
        
        # Test de embedding b√°sico - si esto falla, todo falla
        test_embedding = engine.get_embedding("test")
        if test_embedding is None:
            return False, "‚ùå No se puede generar embedding - modelo corrupto"
        
        if len(test_embedding) != 384:
            return False, f"‚ùå Dimensi√≥n incorrecta: {len(test_embedding)} != 384"
        
        load_time = time.time() - start_time
        return True, f"‚úÖ Modelo cargado correctamente ({load_time:.2f}s)"
        
    except Exception as e:
        return False, f"‚ùå Excepci√≥n durante carga: {str(e)}"

def test_similarity_logic() -> tuple[bool, str, list]:
    """
    Test de l√≥gica sem√°ntica: ¬øDetecta similitudes como esperamos?
    
    Returns:
        (success, summary, failed_cases): Resultado, resumen y casos fallidos
    """
    engine = SemanticEngine(model_path=MODEL_PATH)
    engine.load_model()
    
    failed_cases = []
    total_cases = len(CRITICAL_CASES)
    
    for text1, text2, should_be_similar, threshold in CRITICAL_CASES:
        emb1 = engine.get_embedding(text1)
        emb2 = engine.get_embedding(text2)
        
        if emb1 is None or emb2 is None:
            failed_cases.append(f"NULL embedding: '{text1}' o '{text2}'")
            continue
        
        similarity = engine.cosine_similarity(emb1, emb2)
        is_similar = similarity >= threshold
        
        # Verificar expectativa vs realidad
        if is_similar != should_be_similar:
            expected = "similar" if should_be_similar else "diferente"
            failed_cases.append(
                f"'{text1}' vs '{text2}': esperado {expected}, "
                f"obtenido {similarity:.3f} (umbral: {threshold})"
            )
    
    success = len(failed_cases) == 0
    passed = total_cases - len(failed_cases)
    summary = f"‚úÖ {passed}/{total_cases} casos pasaron" if success else f"‚ùå {len(failed_cases)}/{total_cases} casos fallaron"
    
    return success, summary, failed_cases

def test_duplicate_detection() -> tuple[bool, str]:
    """
    Test de detecci√≥n de duplicados: ¬øFunciona la l√≥gica multicapa?
    
    Returns:
        (success, message): Resultado del test
    """
    engine = SemanticEngine(model_path=MODEL_PATH)
    engine.load_model()
    
    # Casos que S√ç deben detectarse como duplicados
    should_detect = [
        ("me gusta star wars", ["adoro star wars", "odio la ciencia ficci√≥n"]),
        ("libros de sanderson", ["novelas de brandon sanderson", "recetas de cocina"])
    ]
    
    # Casos que NO deben detectarse como duplicados
    should_not_detect = [
        ("python programming", ["pasta carbonara", "viajes a marte"])
    ]
    
    failures = []
    
    # Test detecci√≥n positiva
    for query, candidates in should_detect:
        is_dup, match, score, method = engine.is_semantic_duplicate(query, candidates, 0.7)
        if not is_dup:
            failures.append(f"No detect√≥ duplicado: '{query}' deber√≠a coincidir con alguno de {candidates}")
    
    # Test detecci√≥n negativa
    for query, candidates in should_not_detect:
        is_dup, match, score, method = engine.is_semantic_duplicate(query, candidates, 0.7)
        if is_dup:
            failures.append(f"Falso positivo: '{query}' no deber√≠a coincidir con '{match}' (score: {score:.3f})")
    
    success = len(failures) == 0
    message = "‚úÖ Detecci√≥n de duplicados funciona correctamente" if success else f"‚ùå {len(failures)} fallo(s) en detecci√≥n"
    
    return success, message

# =======================================================================
# 4. EJECUCI√ìN PRINCIPAL (MINIMALISTA)
# =======================================================================

def run_semantic_validation() -> bool:
    """
    Ejecuta toda la bater√≠a de pruebas cr√≠ticas.
    
    Returns:
        bool: True si todas las pruebas pasan, False si alguna falla
    """
    print("üß™ VALIDACI√ìN DEL MOTOR SEM√ÅNTICO")
    print("=" * 50)
    
    total_start = time.time()
    all_passed = True
    
    # Test 1: Sanidad b√°sica del modelo
    print("1. Carga del modelo...")
    model_ok, model_msg = test_model_sanity()
    print(f"   {model_msg}")
    if not model_ok:
        print("   ‚ö†Ô∏è ABORTANDO - Modelo no funcional")
        return False
    
    # Test 2: L√≥gica de similitud
    print("\n2. L√≥gica de similitud...")
    sim_ok, sim_msg, failed_cases = test_similarity_logic()
    print(f"   {sim_msg}")
    if not sim_ok:
        print("   Fallos detectados:")
        for case in failed_cases[:3]:  # Solo mostrar primeros 3 fallos
            print(f"     ‚Ä¢ {case}")
        all_passed = False
    
    # Test 3: Detecci√≥n de duplicados
    print("\n3. Detecci√≥n de duplicados...")
    dup_ok, dup_msg = test_duplicate_detection()
    print(f"   {dup_msg}")
    if not dup_ok:
        all_passed = False
    
    # Resultado final
    total_time = time.time() - total_start
    print("\n" + "=" * 50)
    
    if all_passed:
        print(f"‚úÖ TODAS LAS PRUEBAS PASARON ({total_time:.2f}s)")
        print("   El motor sem√°ntico est√° operativo para uso en producci√≥n.")
    else:
        print(f"‚ùå ALGUNAS PRUEBAS FALLARON ({total_time:.2f}s)")
        print("   Revisar configuraci√≥n antes de usar en producci√≥n.")
    
    return all_passed

# =======================================================================
# PUNTO DE ENTRADA
# =======================================================================

if __name__ == "__main__":
    try:
        success = run_semantic_validation()
        exit_code = 0 if success else 1
        exit(exit_code)
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Test interrumpido por usuario")
        exit(130)
        
    except Exception as e:
        print(f"\nüí• ERROR CR√çTICO: {str(e)}")
        exit(1)

# ===============================================
# ESTADO: VECTORIALMENTE PRAGM√ÅTICO
# √öLTIMA ACTUALIZACI√ìN: Cuando dej√© de confiar en que los embeddings no mintieran
# FILOSOF√çA: "Si el test pasa, probablemente funciona. Si falla, definitivamente est√° roto."
# ===============================================
#
#           THIS IS THE 384D WAY... 
#           (validaci√≥n m√≠nima pero suficiente para detectar problemas reales)
#
# ===============================================