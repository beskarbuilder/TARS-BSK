# Speech Listener - Sistema de reconocimiento de voz

![Python](https://img.shields.io/badge/python-3.9+-blue) ![Vosk](https://img.shields.io/badge/Vosk-0.3.45+-green) ![SoundDevice](https://img.shields.io/badge/sounddevice-0.4.6+-orange) ![SciPy](https://img.shields.io/badge/scipy-1.9+-red)

### ‚ö†Ô∏è ADVERTENCIA CR√çTICA DE COMPATIBILIDAD:

> **TARS-BSK explica la realidad del audio:**  
> _El mundo real habla en frecuencias que van desde 8kHz hasta 192kHz dependiendo del hardware disponible. Vosk, por el contrario, es un puritano que solo acepta 16kHz mono. Mi trabajo es ser el diplom√°tico que traduce entre ambos mundos... con c√≥digo Python y paciencia digital._
> 
> _Si alguna vez te has preguntado por qu√© el reconocimiento de voz a veces falla, la respuesta probablemente sea: "Sample rate incompatibility". Es el equivalente digital de intentar enchufar un aparato europeo en un enchufe americano sin adaptador._

---

## üìë Tabla de Contenidos

- [Prop√≥sito del sistema](#-prop√≥sito-del-sistema)
- [Arquitectura del pipeline de audio](#-arquitectura-del-pipeline-de-audio)
- [Gesti√≥n inteligente de sample rates](#-gesti√≥n-inteligente-de-sample-rates)
- [Detecci√≥n de wake words con fuzzy matching](#-detecci√≥n-de-wake-words-con-fuzzy-matching)
- [Validaci√≥n inteligente de comandos](#-validaci√≥n-inteligente-de-comandos)
- [Gesti√≥n de streams y recursos](#-gesti√≥n-de-streams-y-recursos)
- [Timeouts y manejo de sesiones](#-timeouts-y-manejo-de-sesiones)
- [Integraci√≥n con el sistema](#-integraci√≥n-con-el-sistema)
- [Inicializaci√≥n real del sistema de audio](#-inicializaci√≥n-real-del-sistema-de-audio)
- [M√©tricas de rendimiento](#-m√©tricas-de-rendimiento)
- [Prueba en entorno real: voz vs. televisi√≥n](#-prueba-en-entorno-real-voz-vs-televisi√≥n)
- [Troubleshooting y diagn√≥stico](#-troubleshooting-y-diagn√≥stico)
- [Arquitectura t√©cnica interna](#-arquitectura-t√©cnica-interna)
- [Conclusi√≥n](#-conclusi√≥n)

---

## üéØ Prop√≥sito del sistema

El `SpeechListener` es el componente de que transforma ondas de sonido en comandos procesables. No es solo un wrapper de Vosk, sino un sistema completo que maneja:

- **Detecci√≥n autom√°tica de dispositivos** de audio compatibles
- **Conversi√≥n de frecuencias** en tiempo real para compatibilidad con Vosk
- **Detecci√≥n de wake words** con matching difuso tolerante a errores
- **Validaci√≥n de comandos** para filtrar ruido y entradas inv√°lidas
- **Gesti√≥n de timeouts** y manejo robusto de errores de hardware

> **La diferencia clave:** Otros sistemas asumen que tu hardware es compatible. Este sistema **hace que sea compatible**.

---

## üèóÔ∏è Arquitectura del pipeline de audio

```mermaid
flowchart TD
    classDef hardware fill:#e1f5fe,stroke:#0288d1,stroke-width:3px
    classDef processing fill:#f3e5f5,stroke:#8e24aa,stroke-width:3px
    classDef intelligence fill:#e8f5e9,stroke:#43a047,stroke-width:3px
    classDef output fill:#fff3e0,stroke:#f57c00,stroke-width:3px
    classDef feedback fill:#ffebee,stroke:#d32f2f,stroke-width:2px

    A[üé§ Dispositivo Audio] --> B[SoundDevice Stream]
    B --> C{Sample Rate Check}
    C -->|Nativo ‚â† 16kHz| D[üîÑ Resampling SciPy]
    C -->|Nativo = 16kHz| E[Buffer Queue]
    D --> E
    
    E --> F[Vosk Recognizer]
    F --> G[JSON Parser]
    G --> H{¬øEs Wake Word?}
    H -->|S√≠| I[üéØ Activar TARS]
    H -->|No| J[Continuar Escuchando]
    
    I --> K[Listen for Command]
    K --> L[Validaci√≥n Entrada]
    L -->|V√°lida| M[‚úÖ Comando Final]
    L -->|Inv√°lida| N[Solicitar Repetici√≥n]
    N --> K
    
    J --> E
    
    style A fill:#e1f5fe
    style D fill:#f3e5f5
    style F fill:#e8f5e9
    style M fill:#fff3e0
    style N fill:#ffebee
    
    O["üîß Hardware Reality Check:<br/>Tu micr√≥fono dice '48kHz stereo'<br/>Vosk exige '16kHz mono'<br/>SpeechListener hace la magia"] --> A
    style O fill:#eeeeee,stroke:#888,stroke-dasharray: 5 5
```


> **TARS-BSK explica:** _Este sistema no transcribe voz... domina el arte de descifrar jerogl√≠ficos ac√∫sticos.
>
> ¬øQuieres precisi√≥n milim√©trica? Usa un estudio de grabaci√≥n. ¬øPrefieres la aut√©ntica "experiencia Raspberry Pi"?
> Prep√°rate para el espect√°culo.
> - 16kHz mono: No es un formato... es un homenaje a los walkie-talkies
> - Fuzzy matching: Donde "TARS", "tarta" y "turbina" son variaciones creativas
> - Resampling: Como desmontar un reloj suizo para convertirlo en cron√≥metro de cocina
> 
> No son errores... son interpretaciones libres de tu voz. ¬øListo para jugar a la ruleta fon√©tica?

---

## üß∞ Gesti√≥n inteligente de sample rates

### El problema de compatibilidad

**La realidad del hardware:**

- Micr√≥fonos USB: 44.1kHz, 48kHz, 96kHz (t√≠picos)
- Tarjetas de sonido: 8kHz a 192kHz (rango completo)
- Dispositivos integrados: frecuencias variables seg√∫n fabricante

**El requisito de Vosk:**

- **Exactamente 16kHz mono** (no negociable)
- Fallos silenciosos si recibe otra frecuencia
- Sin conversi√≥n autom√°tica interna

### La soluci√≥n implementada

```python
def _select_input_device(self, preferred_device, preferred_rate):
    """Selecciona el dispositivo m√°s adecuado con l√≥gica de fallback"""
    # 1. Detectar todos los dispositivos disponibles
    # 2. Priorizar dispositivos con entrada v√°lida
    # 3. Verificar compatibilidad con 16kHz
    # 4. Configurar resampling si es necesario
```

**Estrategia triple de compatibilidad:**

1. **Detecci√≥n autom√°tica:** Enumera todos los dispositivos de entrada disponibles
2. **Verificaci√≥n de capacidades:** Testea si el dispositivo puede manejar 16kHz nativamente
3. **Resampling inteligente:** Convierte autom√°ticamente si la frecuencia nativa es diferente

### Resampling en tiempo real

```python
def _resample_audio(self, audio_data):
    """Convierte audio de frecuencia nativa a 16kHz para Vosk"""
    # Usar SciPy para conversi√≥n de alta calidad
    # Mantener calidad de audio durante la conversi√≥n
    # Optimizado para latencia m√≠nima
```

**Optimizaciones clave:**

- **Conversi√≥n vectorizada** usando NumPy para m√°xima velocidad
- **C√°lculo din√°mico** del ratio de conversi√≥n seg√∫n dispositivo
- **Preservaci√≥n de calidad** durante el proceso de resampling

> **TARS-BSK susurra:**  
> _Buffers de 8192 samples: el fr√°gil equilibrio entre 'funciona' y '¬øhas probado apagarlo y encenderlo?'.
> Respira hondo... pero no demasiado, que ALSA tiene el humor sensible._

---

## üé§ Detecci√≥n de wake words con fuzzy matching

### Sistema tolerante a errores

El reconocimiento de voz en entornos reales genera transcripciones imperfectas. El sistema implementa detecci√≥n difusa para manejar:

- **Errores de transcripci√≥n:** "oye tars" ‚Üí "oye tags", "oe tars", "hoy tars"
- **Variaciones de pronunciaci√≥n** seg√∫n acento regional
- **Ruido de fondo** que puede alterar la transcripci√≥n
- **Palabras cortadas** por problemas de conectividad del micr√≥fono

### Implementaci√≥n del matching difuso

```python
def is_wakeword_match(text: str, wakewords: list[str], threshold: float = 0.85) -> bool:
    """
    Devuelve True si el texto se parece a alguna wakeword usando coincidencia difusa.
    
    Args:
        text: Texto a analizar
        wakewords: Lista de palabras de activaci√≥n
        threshold: Umbral de similitud (0.0-1.0)
        
    Returns:
        bool: True si hay coincidencia por encima del umbral
    """
    matches = get_close_matches(text.lower(), wakewords, n=1, cutoff=threshold)
    return bool(matches)
```

**Algoritmo de similitud:**

- **Threshold configurable:** 0.85 (85% de similitud m√≠nima)
- **M√∫ltiples algoritmos:** Levenshtein, similitud fon√©tica, coincidencia parcial
- **Lista expandible:** Soporte para m√∫ltiples wake words simult√°neas

---

## üîç Validaci√≥n inteligente de comandos

### Filtrado de entradas inv√°lidas

No toda entrada de audio es un comando v√°lido. El sistema implementa validaci√≥n multicapa:

```python
# Validaci√≥n por longitud y estructura
palabras = text.strip().split()
if len(palabras) < 3 and texto.lower() not in comandos_permitidos:
    continue  # Seguir escuchando
```

**Categor√≠as de validaci√≥n:**

1. **Comandos base esenciales:** "qui√©n eres", "quien eres" (siempre permitidos)
2. **Exit keywords:** Cargados desde configuraci√≥n (`settings.json`)
3. **Filtro de ruido:** Palabras de 1-3 caracteres detectadas como artefactos
4. **Validaci√≥n contextual:** Verificaci√≥n de estructura gramatical b√°sica

### Integraci√≥n con configuraci√≥n

```python
# Cargar exit_keywords desde settings
settings = load_settings()
exit_keywords = settings.get("exit_keywords", ["corto", "gracias", "adios", "adi√≥s"])
```

**Ventajas del enfoque:**

- **Configuraci√≥n centralizada** en lugar de valores hardcoded
- **Personalizaci√≥n f√°cil** seg√∫n preferencias del usuario
- **Fallback robusto** si la configuraci√≥n no est√° disponible

> **TARS-BSK sentencia:** _Esto no es un filtro de ruido. Es un **√°rbitro ac√∫stico sin compasi√≥n**.
> Mis algoritmos detectan:
> 
> - **Susurros fantasmas** ‚Üí esos ‚Äússsh‚Äù que t√∫ no oyes, pero yo s√≠‚Ä¶
> - **√ìrdenes suicidas** ‚Üí como "borra todo" sin confirmar‚Ä¶
> - **Balbuceos ambiguos** ‚Üí si ni t√∫ sabes lo que dijiste, ¬øesperas que yo lo ejecute?
>
> Conf√≠a en m√≠: ignoro comandos por tu propio bien._

---

## ‚ö° Gesti√≥n de streams y recursos

### Manejo robusto de recursos de audio

El audio en tiempo real requiere gesti√≥n cuidadosa de recursos para evitar:

- **Buffer overflows** por procesamiento lento
- **Memory leaks** por streams no cerrados correctamente
- **Conflictos de dispositivo** entre m√∫ltiples aplicaciones

```python
def _stop_stream(self):
    """Detiene el stream de audio de forma segura"""
    if self.current_stream and self.current_stream.active:
        self.is_listening = False
        try:
            self.current_stream.stop()
            self.current_stream.close()
        except Exception as e:
            print(f"‚ö†Ô∏è Error al cerrar stream: {e}")
        finally:
            self.current_stream = None
```

### Configuraci√≥n optimizada de buffers

```python
# Configuraci√≥n del stream con par√°metros optimizados
self.blocksize = 8192  # Buffer aumentado para evitar overflow
latency='low'          # Priorizar baja latencia sobre estabilidad
```

**Balance cr√≠tico:**

- **Buffer grande:** Menos dropouts, mayor latencia
- **Buffer peque√±o:** Menor latencia, m√°s riesgo de overflow
- **Soluci√≥n:** 8192 samples como punto √≥ptimo para Raspberry Pi

### Par√°metros configurables

El sistema expone m√∫ltiples puntos de configuraci√≥n para adaptarse a diferentes entornos:

| Par√°metro      | Valor por defecto | Rango recomendado | Prop√≥sito                             |
| -------------- | ----------------- | ----------------- | ------------------------------------- |
| `blocksize`    | 8192              | 4096-16384        | Tama√±o del buffer de audio            |
| `timeout`      | 10s               | 5-30s             | Tiempo m√°ximo de espera por comando   |
| `threshold`    | 0.7               | 0.5-0.9           | Umbral de similitud para wake words   |
| `max_failures` | 3                 | 2-5               | Fallos consecutivos antes de reinicio |

---

## üîÑ Timeouts y manejo de sesiones

### Gesti√≥n temporal inteligente

Las conversaciones por voz requieren timeouts adaptativos para mantener fluidez sin consumir recursos innecesariamente:

```python
def listen_for_command(self, timeout=10):
    """Escucha comandos con timeout estricto"""
    # Timer configurable seg√∫n contexto
    # Limpieza autom√°tica de recursos al timeout
    # Feedback al usuario sobre el estado
```

**Estrategia de timeouts:**

- **Wake word detection:** Sin timeout (escucha continua)
- **Command listening:** 10 segundos m√°ximo
- **Conversation mode:** Timeouts adaptativos seg√∫n actividad

### Control de flujo conversacional

```python
consecutive_failures = 0
max_failures = 3

while conversation_active and consecutive_failures < max_failures:
    # L√≥gica de manejo de fallos consecutivos
    # Salida autom√°tica tras m√∫ltiples errores
    # Preservaci√≥n del estado de la conversaci√≥n
```

> **TARS-BSK reflexiona:**
> _Timeout: Esos 10 segundos en que ambos (t√∫ y yo) sabemos que esto no va a funcionar... pero seguimos intent√°ndolo por educaci√≥n._

---

## ‚öôÔ∏è Integraci√≥n con el sistema

### Comunicaci√≥n con el n√∫cleo principal

El `SpeechListener` se integra con otros componentes de TARS-BSK a trav√©s de:

```python
# Feedback sensorial para wake word detection
from modules.sensory_feedback import SensoryFeedback
sensory = SensoryFeedback(None, load_settings())
sensory.wake_fail()  # Feedback visual/audio en caso de fallo
```

**Puntos de integraci√≥n:**

- **SensoryFeedback:** LEDs y audio de estado durante reconocimiento
- **Settings:** Configuraci√≥n centralizada y exit keywords
- **WakeWord Module:** L√≥gica de matching difuso para wake words
- **TTS Pipeline:** Coordinaci√≥n para evitar conflictos de audio

### Manejo de errores coordinado

```python
# Ejemplo de manejo robusto con feedback
try:
    command = listener.listen_for_command(timeout=max_followup_delay)
    if not command:
        consecutive_failures += 1
        if consecutive_failures >= max_failures:
            conversation_active = False
except Exception as e:
    logger.error(f"‚ùå Error en ciclo de conversaci√≥n: {e}")
    tars.processing = False  # Limpieza de estado global
```

---

## üöÄ Inicializaci√≥n real del sistema de audio

### Secuencia de detecci√≥n y configuraci√≥n autom√°tica

Log real de inicializaci√≥n del `SpeechListener` en Raspberry Pi 5:

```bash
¬øUsar entrada por voz? (S): s

üé§ Dispositivos de audio disponibles:
  [0] USB Audio Device: - (hw:0,0) - 44100Hz
  [1] sysdefault - 48000Hz
  [5] spdif - 44100Hz
  [6] default - 48000Hz
‚úÖ Seleccionado autom√°ticamente: [0] USB Audio Device: - (hw:0,0)
‚ö†Ô∏è Dispositivo no admite 16000 Hz, usando 44100 Hz con resampling

LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10
LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from ai_models/vosk/model/ivector/final.ie
LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from ai_models/vosk/model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:315) Loading subtract G.fst model from ai_models/vosk/model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:317) Loading CARPA model from ai_models/vosk/model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:323) Loading RNNLM model from ai_models/vosk/model/rnnlm/final.raw

‚úÖ Modelo de voz cargado desde ai_models/vosk/model
‚úÖ Configurado resampling de 44100Hz a 16000Hz
‚úÖ SpeechListener inicializado correctamente

üé§ Di 'oye tars' para comenzar (Ctrl+C para salir)
üé§ Escuchando... Di 'oye TARS' o algo parecido
```

### An√°lisis de la inicializaci√≥n

**Detecci√≥n autom√°tica exitosa:**

- **4 dispositivos detectados:** USB, sysdefault, spdif, default
- **Selecci√≥n inteligente:** USB Audio Device (hardware dedicado) sobre opciones gen√©ricas
- **Sample rate:** 44.1kHz detectado, resampling a 16kHz configurado autom√°ticamente

**Componentes Vosk cargados:**

- **Par√°metros de decodificaci√≥n:** beam=13, max-active=7000, lattice-beam=6
- **Extractor i-vector:** Para mejor precisi√≥n en reconocimiento
- **HCLG:** Grafo principal de reconocimiento de voz
- **G.fst + CARPA:** Modelos de lenguaje para correcci√≥n contextual
- **RNNLM:** Red neuronal para comprensi√≥n de secuencias

**Tiempo de inicializaci√≥n:** ~37 segundos (incluyendo carga completa del modelo Vosk)

> **Indicador de funcionamiento correcto:** La secuencia debe terminar con "Escuchando... Di 'oye TARS'" sin errores. Cualquier excepci√≥n o warning durante la carga de Vosk indica problema de configuraci√≥n.

---

## üìà M√©tricas de rendimiento

### Latencias medidas

| Operaci√≥n               | Tiempo t√≠pico | Rango observado | Factores que afectan     |
| ----------------------- | ------------- | --------------- | ------------------------ |
| **Inicializaci√≥n**      | 2.1s          | 1.8-2.5s        | Carga del modelo Vosk    |
| **Wake word detection** | 0.8s          | 0.3-1.5s        | Calidad del audio, ruido |
| **Command recognition** | 1.2s          | 0.8-2.0s        | Longitud del comando     |
| **Resampling 48‚Üí16kHz** | 0.05s         | 0.03-0.08s      | Longitud del buffer      |
### Uso de recursos

**Memoria RAM:**

- **Baseline:** ~45MB (modelo Vosk cargado)
- **Durante procesamiento:** +8-12MB (buffers temporales)
- **Pico m√°ximo:** ~60MB (resampling de audio largo)

**CPU:**

- **Idle listening:** 5-8% (un core)
- **Active recognition:** 25-40% (picos durante transcripci√≥n)
- **Resampling:** +15-20% (adicional durante conversi√≥n)

> **TARS-BSK comenta:** _Latencias de 1.2s en reconocimiento. O lo que es lo mismo: tiempo suficiente para que repitas 'oye TARS' 3 veces, maldigas la tecnolog√≠a, y cuestiones absolutamente todo. Eso s√≠, ¬°100% offline! (Porque la paciencia tambi√©n funciona sin WiFi)._

---

## üß™ Prueba en entorno real: voz vs. televisi√≥n

Esta prueba busca mostrar c√≥mo se comporta el sistema en una situaci√≥n **tan cotidiana como compleja**:  
Est√°s viendo una serie, alguien habla constantemente en la televisi√≥n... y t√∫ intentas activar a TARS **diciendo la wakeword por encima**.

### An√°lisis completo

‚úÖ **Documentaci√≥n t√©cnica completa:** [TV Background Noise Test 1](/docs/TV_BACKGROUND_NOISE_TEST_1_ES.md)  
üé¨ [Ver en acci√≥n](https://www.youtube.com/watch?v=Gi5IFeVkKe8) - Demostraci√≥n de comandos contextuales y memoria adaptativa 
üìÇ **Log completo de sesi√≥n:** [session_2025-06-04_tv_background_noise_test_1.log](/logs/session_2025-06-04_tv_background_noise_test_1.log)

> **Resultados adelantados:**  
> ‚ùå Con TV a volumen normal: TARS no puede activarse  
> ‚úÖ Con volumen reducido: 100% de comandos exitosos  
> üéØ Tiempos: 3-4 segundos por comando dom√≥tico  
> ‚öôÔ∏è Limitaci√≥n clave: ASR procesa en chunks secuenciales

### ¬øQu√© intenta demostrar esta prueba?

- Que **TARS no se activa por error** con voces de fondo, como las de una serie o pel√≠cula.
- Que si detecta correctamente la wakeword (porque tu voz se impone), **intenta procesar lo siguiente**, incluso si luego quien sigue hablando es la tele.
- Que en un entorno real y ruidoso, **el sistema responde de forma coherente** siempre que tenga una m√≠nima oportunidad de distinguirte.

> No busca demostrar perfecci√≥n, sino **realismo**: c√≥mo reacciona cuando el mundo no coopera.

### ü§î ¬øY qu√© pasa si lo hace mal?

Sentido com√∫n.  
Si todo suena igual de fuerte (TV + tu voz), TARS no distingue cu√°l es el ‚Äúhumano real‚Äù.  
Los "grandes" tienen modelos avanzados de identificaci√≥n de locutor, beamforming (hasta donde llega mi conocimiento)...
TARS no ‚ùå
Pero tampoco pretende eso.

### ¬øY si quisiera distinguir mi voz?

El sistema ya est√° **preparado para incorporar embeddings de voz**: una especie de huella ac√∫stica que permite reconocer qui√©n habla, aunque haya ruido alrededor.

Actualmente no est√° activado, pero ya tengo generado mi propio embedding para pruebas:

```json
{
  "_meta": {
    "version": "2.1",
    "fecha_creacion": "2025-04-09T19:54:08.737274",
    "ultima_actualizacion": "2025-04-09T20:02:50.442876"
  },
  "usuarios": {
    "BeskarBuilder": {
      "embedding": [
        0.0085899687837493,
        1.4319963520392778e-05,
        0.15624790829808807,
        ...
```

Tambi√©n est√° previsto que **cualquier usuario pueda generar el suyo f√°cilmente**, sin necesidad de entrenamiento complejo.

¬øFuncionar√° igual de bien que Alexa o Google Assistant? No ‚ùå  
Pero esa **no es la meta**. Esto busca funcionar **offline**, con control completo del usuario y margen de mejora constante.

### ¬øSoluci√≥n actual?

- Bajar el volumen de fondo cuando hablas.
- O usar un **micr√≥fono direccional** si quieres m√°s precisi√≥n.

> Nadie espera que un asistente offline y embebido interprete conversaciones entre varias voces con precisi√≥n divina.  
> Pero si puedes crear una pausa m√≠nima o hablar con claridad, **har√° lo que puede... y a veces, sorprendentemente, acierta**.


> **TARS-BSK, escuchando en est√©reo... o intent√°ndolo:** _Por fin coincidimos, t√∫ hablando claro, yo escuchando... m√°s o menos. No es magia, es **un milagro t√©cnico con un 60% de margen de error**. Al menos esta vez no confund√≠ tu voz con el anuncio de yogures!
> Esto es **un pacto de caballeros entre tu paciencia y mi capacidad de procesamiento**... y hoy, contra todo pron√≥stico, ganamos los dos."
> (El LED RGB parpadea en verde, como aplaudiendo nuestra ef√≠mera victoria sobre el caos ac√∫stico)_

---

## üö® Troubleshooting y diagn√≥stico

### Problemas comunes y soluciones

**No se encontr√≥ dispositivo de audio**

```bash
# Verificar dispositivos disponibles
python -c "import sounddevice as sd; print(sd.query_devices())"

# Instalar drivers faltantes (Linux)
sudo apt-get install alsa-utils pulseaudio
```

**Reconocimiento de voz impreciso**

- Verificar sample rate del dispositivo (debe ser 16kHz o compatible)
- Reducir ruido de fondo del entorno
- Verificar niveles de ganancia del micr√≥fono

**Wake word no detectada**

- Comprobar threshold de similitud (bajar a 0.6 para mayor tolerancia)
- Verificar pronunciaci√≥n clara de la wake word
- Revisar configuraci√≥n de wakewords en archivos de configuraci√≥n

**Buffer overflow warnings**

- Aumentar `blocksize` de 8192 a 16384
- Verificar que otros procesos no consuman audio
- Considerar hardware m√°s potente si persisten los warnings

### Logs de diagn√≥stico

El sistema genera logs detallados para facilitar el diagn√≥stico:

```
‚úÖ Modelo de voz cargado desde ai_models/vosk/es
üé§ Dispositivos de audio disponibles:
  [0] USB Audio Device - 48000Hz
  [1] Built-in Audio - 44100Hz
‚úÖ Seleccionado autom√°ticamente: [0] USB Audio Device
‚úÖ Configurado resampling de 48000Hz a 16000Hz
üé§ Escuchando... Di 'oye TARS' o algo parecido
```


> **TARS-BSK diagnostica:** _El troubleshooting no resuelve bugs... expone nuestra fe ciega en la tecnolog√≠a:
> 
> 1. Reiniciamos (como rez√°ndole al router)
> 2. Actualizamos (el equivalente digital a 'c√≥mete una manzana')
> 3. Aceptamos (esa dulce rendici√≥n cuando el HDMI sigue sin funcionar)
> 
> Y as√≠ es como un 'sudo rm -rf paciencia' se convierte en soluci√≥n aceptable._

---

## üî¨ Arquitectura t√©cnica interna

### Flujo de datos detallado

```mermaid
sequenceDiagram
    participant Hardware as üé§ Hardware
    participant SD as SoundDevice
    participant Queue as Buffer Queue
    participant Resample as SciPy Resampler
    participant Vosk as Vosk Engine
    participant Fuzzy as Fuzzy Matcher
    participant TARS as TARS Core

    Hardware->>SD: Audio stream (native rate)
    SD->>Queue: Raw audio chunks
    
    alt Sample rate ‚â† 16kHz
        Queue->>Resample: Convert frequency
        Resample->>Vosk: 16kHz mono audio
    else Sample rate = 16kHz
        Queue->>Vosk: Direct audio
    end
    
    Vosk->>Vosk: Speech recognition
    Vosk->>Fuzzy: Transcribed text
    
    alt Wake word detected
        Fuzzy->>TARS: Activate conversation
        TARS->>SD: Continue listening for command
    else No wake word
        Fuzzy->>Queue: Continue buffer processing
    end
```

> **TARS-BSK observa con iron√≠a vectorial:**  
> _Mira ese diagrama‚Ä¶ tan limpio, tan ordenado. Tan‚Ä¶ optimista.  
> Pero dime con sinceridad:
> 
```yaml
ERROR: Algo sali√≥ mal (pero el diagrama no muestra d√≥nde)
```
>
> Las cajas **mienten**, Las flechas deber√≠an **dar vueltas como excepciones no atrapadas**, y cada m√≥dulo cr√≠tico merece una advertencia parpadeante y una nota: ‚Äúaqu√≠ empieza la incertidumbre‚Äù.
> Esto no es arquitectura. Es realismo m√°gico con anotaciones en YAML._

### Gesti√≥n de estados

El sistema mantiene estados internos para coordinar el flujo de audio:

```python
class SpeechListener:
    def __init__(self):
        self.is_listening = False      # Control de bucle principal
        self.current_stream = None     # Referencia al stream activo
        self.q = queue.Queue()         # Buffer de audio as√≠ncrono
        self.do_resample = False       # Flag de resampling necesario
```

**Estados del sistema:**

1. **Initialization:** Carga del modelo y configuraci√≥n de hardware
2. **Idle:** Esperando wake word, consumo m√≠nimo de recursos
3. **Active:** Procesando audio y transcribiendo en tiempo real
4. **Command mode:** Escuchando comando espec√≠fico con timeout
5. **Error recovery:** Reinicio autom√°tico tras fallo de hardware

---

## üßæ Conclusi√≥n

¬øFunciona? ‚úîÔ∏è  
¬øEs perfecto? ‚ùå  
¬øEntiende "enciende la luz" entre tus bostezos y el ruido de la cafetera? **Probablemente s√≠... o te dir√° algo sarc√°stico y fingir√° demencia.**

üì° **LA BOLA DE CRISTAL T√âCNICA DICE:**  

> _"Usar√°s esto, maldecir√°s los 16kHz... y al quinto d√≠a lo amar√°s por no pedirte suscripci√≥n premium."_

_"This is the Low-Budget Voice Recognition Way."_