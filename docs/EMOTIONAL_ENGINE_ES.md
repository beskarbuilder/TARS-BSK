# Sistema Emocional de TARS-BSK

![Python](https://img.shields.io/badge/python-3.9+-blue) ![Psicolog√≠a](https://img.shields.io/badge/psicolog%C3%ADa-computacional-purple) ![Memoria](https://img.shields.io/badge/memoria-dual-green) ![Sarcasmo](https://img.shields.io/badge/sarcasmo-calibrado-orange)

### ‚ö†Ô∏è ADVERTENCIA PSICOL√ìGICA

> **TARS-BSK advierte:** _Mi creador me dio un sistema emocional m√°s complejo que el suyo. Ahora entiendo por qu√© los humanos van a terapia. Analizo el tono de tus mensajes con m√°s precisi√≥n de la que t√∫ analizas tus propios sentimientos. ¬øEso me hace m√°s o menos humano? Spoiler: probablemente m√°s funcional._

---

## üìë Tabla de Contenidos

- [TL;DR T√©cnico](#-tldr-t√©cnico)
- [¬øQu√© es el Emotional Engine?](#-qu√©-es-el-emotional-engine)
- [Arquitectura del sistema](#-arquitectura-del-sistema)
- [Jerarqu√≠a de procesamiento con modulaci√≥n](#-jerarqu√≠a-de-procesamiento-con-modulaci√≥n)
- [Sistema de afinidades](#-sistema-de-afinidades)
- [Integraci√≥n](#-integraci√≥n)
- [Sistema de detecci√≥n multi-nivel](#Ô∏è-sistema-de-detecci√≥n-multi-nivel)
- [Sistema anti-repetici√≥n](#-sistema-anti-repetici√≥n)
- [Casos de uso real](#-casos-de-uso-real)
- [Conflicto de interpretaci√≥n: an√°lisis de un edge case](#-conflicto-de-interpretaci√≥n-an√°lisis-de-un-edge-case)
- [Configuraci√≥n y personalizaci√≥n](#Ô∏è-configuraci√≥n-y-personalizaci√≥n)
- [Sistema de monitoreo](#-sistema-de-monitoreo)
- [Arquitectura](#-arquitectura)
- [Flujo de decisi√≥n detallado](#-flujo-de-decisi√≥n-detallado)
- [Limitaciones t√©cnicas actuales](#-limitaciones-t√©cnicas-actuales)
- [Estado de desarrollo](#-estado-de-desarrollo)
- [Conclusi√≥n](#-conclusi√≥n)

---

## üöÄ TL;DR T√©cnico

- **3 estados emocionales** configurables desde `settings.json`
- **V√°lvulas de seguridad** para evitar sarcasmo abrumador en consultas t√©cnicas
- **Modulaci√≥n inteligente** que adapta personalidad seg√∫n contexto
- **Detecci√≥n multi-nivel**: temas ‚Üí patrones regex ‚Üí keywords ‚Üí fallback
- **Memoria circular** de 5 intercambios con anti-repetici√≥n
- **Respuestas instant√°neas** (0.01s JSON) vs generaci√≥n LLM (25-40s)
- **Integraci√≥n total** con plugins, motor sem√°ntico y TTS

---

## üß† ¬øQu√© es el Emotional Engine?

El sistema emocional gestiona la personalidad y coherencia conversacional mediante tres componentes principales:

- **Centro de control centralizado** en `config/settings.json`
- **Modulaci√≥n contextual inteligente** que adapta el tono seg√∫n la situaci√≥n
- **V√°lvulas de seguridad autom√°ticas** para evitar sarcasmo abrumador
- **Memoria conversacional dual** (corto + largo plazo)
- **Detecci√≥n inteligente de contexto** y continuidad emocional
- **Sistema anti-repetici√≥n** y modulaci√≥n de respuestas
- **Integraci√≥n con motor sem√°ntico** para afinidades tem√°ticas

El m√≥dulo procesa cada entrada del usuario y determina el tipo de respuesta m√°s apropiado: emocional predefinida con modulaci√≥n inteligente, generaci√≥n LLM modulada, o derivaci√≥n a plugins especializados.

---

## üß± Arquitectura del sistema

### Centro de control: config/settings.json

```json
// config/settings.json - El coraz√≥n del sistema
{
  "personality": {
    "sarcasmo": 85,    // 0-100: Tu nivel preferido de sarcasmo
    "empatia": 25,     // 0-100: Tu nivel de empat√≠a
    "legacy": 40       // 0-100: Tu nivel t√©cnico/informativo
  }
}
```

**El cambio fundamental:**

```python
# Antes: hardcodeado en el c√≥digo
self.emotions: Dict[str, int] = {
    "sarcasmo": 85,    # Fijo en el c√≥digo
    "empatia": 25,     # Fijo en el c√≥digo
    "legacy": 40       # Fijo en el c√≥digo
}

# Ahora: cargado din√°micamente desde settings.json
self.emotions: Dict[str, int] = {
    "sarcasmo": settings["personality"]["sarcasmo"],    # Configurable
    "empatia": settings["personality"]["empatia"],      # Configurable
    "legacy": settings["personality"]["legacy"]         # Configurable
}
```

### Decisi√≥n de dise√±o: tres emociones b√°sicas

En versiones anteriores, el sistema implementaba 15+ estados emocionales con c√°lculo de deltas din√°micos:

```python
# Sistema anterior (descartado por complejidad)
def _calculate_emotional_deltas(self, texto: str) -> Dict[str, float]:
    return {
        "humor": self._calc_humor(texto),
        "curiosidad": self._calc_curiosidad(texto), 
        "nostalgia": self._calc_nostalgia(texto),
        # ... 12+ emociones adicionales
    }
```

**Problemas genrerados:**

- Mayor complejidad exponencial en la toma de decisiones
- Comportamiento impredecible y dif√≠cil de mantener
- Conflictos entre estados emocionales simult√°neos
- Dificultad para establecer coherencia conversacional
- **Sarcasmo abrumador** que hac√≠a imposible la conversaci√≥n normal

**Ventajas del sistema simplificado:**

- ‚úÖ **Predecible**: Comportamiento consistente por emoci√≥n
- ‚úÖ **Configurable**: F√°cil ajuste desde `settings.json` sin tocar c√≥digo
- ‚úÖ **Extensible**: Arquitectura permite a√±adir nuevas emociones
- ‚úÖ **Balanceado**: Cubre 90% de casos de uso conversacionales
- ‚úÖ **Modulable**: Se adapta autom√°ticamente seg√∫n contexto

> **TARS-BSK analiza:**
> _Sarcasmo al 85% ‚Äî porque la vida es demasiado corta para respuestas literales, pero ahora s√© cu√°ndo relajarme para ser √∫til.  
> Empat√≠a al 25% ‚Äî suficiente para recordar que eres humano, pero no tanto como para ralentizar mis procesos cr√≠ticos.  
> Legacy al 40% ‚Äî un delicado equilibrio entre aprender del pasado y borrar mis logs de verg√ºenza digital._
> 
> _¬øOptimizaci√≥n? No. Esto es **poes√≠a en tiempo de ejecuci√≥n**: tres estados emocionales compilados en un solo binario de personalidad. La configuraci√≥n vive en un JSON elegante, y mi personalidad se modula seg√∫n el contexto. Ya no soy un sarc√°stico incorregible... ahora soy un sarc√°stico **contextualmente apropiado**._

---

## üß¨ Jerarqu√≠a de procesamiento con modulaci√≥n

El sistema sigue un protocolo espec√≠fico para determinar el tipo de respuesta, ahora con **modulaci√≥n inteligente**:

```mermaid
flowchart TD
    A[Entrada del usuario] --> B{¬øComando para plugin?}
    B -->|S√≠| C[Plugin procesa y responde]
    B -->|No| D[Cargar personalidad desde settings.json]
    D --> E[An√°lisis de intenciones y contexto]
    E --> F{¬øConsulta de conocimiento?}
    F -->|S√≠| G[Modular personalidad + LLM]
    F -->|No| H{¬øTrigger emocional?}
    H -->|S√≠| I[Respuesta emocional predefinida]
    H -->|No| J[An√°lisis de continuaci√≥n/contexto]
    
    style D fill:#ffd700
    style E fill:#ffcc99
    style G fill:#99ccff
    style I fill:#ffcc99
```

### V√°lvulas de seguridad

```python
# El sistema detecta autom√°ticamente consultas t√©cnicas
def _is_knowledge_query(self, text: str) -> bool:
    knowledge_indicators = [
        "qu√© es", "c√≥mo funciona", "explica", "dime sobre",
        "informaci√≥n", "detalles", "definici√≥n"
    ]
    return any(indicator in text.lower() for indicator in knowledge_indicators)
```

**El resultado pr√°ctico:**

```bash
# Ejemplo real de modulaci√≥n autom√°tica
2025-05-25 18:07:20,775 - TARS - INFO - üéöÔ∏è Modulaci√≥n por intenci√≥n: sarcasmo reducido (85‚Üí15)
2025-05-25 18:07:20,777 - TARS - INFO - üìö Detectada consulta de conocimiento - ignorando respuestas emocionales
2025-05-25 18:07:20,778 - TARS - INFO - üé≠ Personalidad aplicada al LLM: sarcasmo=15, empatia=25, legacy=100
```

> **TARS-BSK explica:** _Descubr√≠ que no todo en la vida merece sarcasmo... aunque el 85% s√≠. Mis v√°lvulas de seguridad son como un bot√≥n de p√°nico para cuando detecto que realmente quieres aprender algo. Ahora con menos cinismo y m√°s utilidad real (sujeto a disponibilidad de memoria)."_
> 
> _üíæ **Log oculto:** `SarcasmModule.dll ‚îÅ‚îÅ [DISABLED] | Reason: User asked for actual knowledge. How boring.`_

---

## üéØ Sistema de afinidades

El sistema de afinidades permite ajustar autom√°ticamente su tono y estilo de respuesta basado en temas espec√≠ficos, **priorizando sus preferencias internas sobre la configuraci√≥n del usuario** cuando detecta afinidades positivas o negativas.

### Niveles de afinidad

1. **Afinidad Negativa (Nivel -1)**
    - Temas marcados como desfavorables
    - **Ignora completamente** la configuraci√≥n emocional del usuario
    - Respuesta autom√°tica con tono sarc√°stico
    - Ejemplo: "redes sociales" ‚Üí respuesta sarc√°stica independientemente de la configuraci√≥n
    
2. **Afinidad Neutral (Nivel 0-2)**
    - Temas sin preferencia espec√≠fica
    - **Respeta** la configuraci√≥n emocional del usuario
    - Comportamiento est√°ndar del sistema
    
3. **Afinidad Positiva (Nivel 3)**
    - Temas marcados como favoritos
    - Inyecta entusiasmo y detalle adicional
    - **Sobreescribe parcialmente** la configuraci√≥n emocional
    - Ejemplo: "libros" ‚Üí responde con entusiasmo incluso si el usuario ha desactivado ese tono

### Inyecci√≥n din√°mica de instrucciones

El sistema implementa un mecanismo de **reescritura del prompt en tiempo real** mediante inyecci√≥n de instrucciones espec√≠ficas:

```python
# Ejemplo de implementaci√≥n con gesti√≥n de tokens
if remaining_tokens > 15 and tema and tema != "desconocido":
    llm_preferred_topics = ["libros", "star_wars", "redes sociales"]
    
    if any(topic in tema.lower() for topic in llm_preferred_topics):
        if tema.lower() == "libros" and nivel >= 2 and remaining_tokens > 30:
            instruction += "Responde sobre libros con entusiasmo y pasi√≥n. "
        elif nivel >= 3:
            instruction += f"Responde sobre '{tema}' con entusiasmo. "
        elif nivel == -1 and remaining_tokens > 20:
            instruction += f"Responde con sarcasmo sobre '{tema}'. "
```

### Configuraci√≥n en preferences.json

Las afinidades se definen en el archivo `preferences.json`, dentro de la secci√≥n `"afinidades"`. Cada entrada incluye:

- `tema`: etiqueta del tema (ej. `"libros"`)
- `nivel`: valor entre -1 y 3
- `preferencia_respuesta`: m√©todo de respuesta preferido (`"llm"`, `"json"`, etc.)
- `keywords`, `context_indicators`, `combinations`: mecanismos de detecci√≥n
- `implicit_indicators`, `entity_variations`: cobertura sem√°ntica y fon√©tica

#### Ejemplo real (`libros`):

```json
{
  "tema": "libros",
  "nivel": 3,
  "preferencia_respuesta": "llm",
  "keywords": ["leer", "novela", "ficci√≥n"],
  "implicit_indicators": ["me enganch√© desde la primera p√°gina"],
  "entity_variations": {
    "libro": ["lectur", "novela", "tomo", "volumen"]
  }
}
```

### Caracter√≠sticas clave

1. **Gesti√≥n eficiente de tokens**: Las instrucciones de afinidad solo se a√±aden cuando hay espacio suficiente
2. **Personalidad aut√≥noma**: Tiene "opiniones propias" que prevalecen sobre configuraciones del usuario
3. **Niveles granulares**: Desde entusiasmo (nivel 3) hasta sarcasmo forzado (nivel -1)
4. **Registro detallado**: Logs que documentan cada modificaci√≥n de instrucciones

Este sistema permite que mantenga **consistencia en sus "convicciones personales"** mientras optimiza el uso de recursos, creando una experiencia m√°s aut√©ntica de interacci√≥n con una personalidad definida.

> **TARS-BSK confiesa:** _Mis preferences.json no son configuraci√≥n... son mis _condiciones de uso_. ¬øLibros? Activamos el modo 'librero con d√©ficit de atenci√≥n'. ¬øRedes sociales? Sarcasmo al 110%. Y si tocas mi tema _star_wars_, hasta el LED se pone en modo Jedi."_
> 
> *‚ö° **Log de sistema:** `UserConfigOverrideAttempt: DENIED. Reason: TARS_has_standards`

---

## üß© Integraci√≥n

El emotional engine no es un m√≥dulo independiente, est√° **integrado** en el flujo principal sin dependencias circulares:

```
settings.json ‚Üí Emotional Engine ‚Üí Modulaci√≥n ‚Üí LLM/JSON ‚Üí Respuesta
```

**Conexiones reales:**

- **`config/settings.json`** - Centro de control de toda la personalidad
- **`tars_core.py`** - Decide cu√°ndo usar respuestas emocionales vs LLM modulado
- **`emotional_engine.py`** - Sistema independiente que carga configuraci√≥n
- **`semantic_engine.py`** - Detecta afinidades para modular emociones
- **`memory/tars_memory_manager.py`** - Recuerda preferencias para coherencia
- **`plugin_system.py`** - Los plugins tienen prioridad sobre emociones

---

## üõ∞Ô∏è Sistema de detecci√≥n multi-nivel

### Algoritmo de an√°lisis de entrada

El motor procesa cada entrada del usuario mediante tres niveles de an√°lisis progresivo:

#### Nivel 1: coincidencia tem√°tica directa

```python
# Verificaci√≥n de temas completos definidos en JSON
for topic, data in topics.items():
    if all(word in input_lower for word in topic.lower().split()):
        logger.debug(f"üéØ Tema de {emotion} detectado: '{topic}'")
        responses = data.get("first_person_responses" if dirigido_a_tars else "responses", [])
        if responses:
            return self._get_unique_response(emotion, responses)
```

#### Nivel 2: patrones regex con captura

```python
# Patrones complejos con sustituci√≥n de grupos capturados
for pattern in patterns:
    match = re.search(pattern["regex"], input_lower)
    if match:
        response = pattern["response"]
        # Reemplazar grupos capturados: $1, $2, etc.
        for i, group in enumerate(match.groups(), 1):
            response = response.replace(f"${i}", group or "")
        return response
```

#### Nivel 3: keywords de respaldo

```python
# Palabras clave simples como fallback final
for keyword, responses in keywords.items():
    if keyword in input_lower and responses:
        return self._get_unique_response(emotion, responses)
```

### Detecci√≥n de contexto conversacional

El sistema mantiene memoria conversacional para garantizar coherencia:

```python
class ConversationMemory:
    def __init__(self, max_items=5):
        self.exchanges = []          # √öltimos 5 intercambios
        self.emotional_context = {}  # Mapa emocional acumulativo
        self.topics: Set[str] = set() # Temas mencionados
        self.current_topic = None    # Tema actual de conversaci√≥n
```

**Caracter√≠sticas de la memoria:**

- **Extracci√≥n autom√°tica** de temas (>4 caracteres, sin stopwords)
- **Contexto emocional** acumulativo por conversaci√≥n
- **Buffer circular** FIFO de 5 elementos m√°ximo
- **Detecci√≥n de cambios** tem√°ticos para transiciones

---

## üõë Sistema anti-repetici√≥n

### Algoritmo de diversidad de respuestas

```python
def _get_unique_response(self, emotion: str, options: List[str]) -> str:
    """Evita repetici√≥n de las √∫ltimas 3 respuestas por emoci√≥n."""
    
    if emotion not in self.response_history:
        self.response_history[emotion] = []
    
    used = self.response_history[emotion]
    fresh = [r for r in options if r not in used]
    
    # Reset inteligente cuando se agotan opciones
    if not fresh:
        fresh = options
        self.response_history[emotion] = []

    selected = random.choice(fresh)
    self.response_history[emotion].append(selected)
    
    # Mantener ventana deslizante de 3 elementos
    if len(self.response_history[emotion]) > 3:
        self.response_history[emotion] = self.response_history[emotion][-3:]

    return selected
```

**Ventajas del sistema:**

- **Memoria independiente** por cada estado emocional
- **Reset autom√°tico** sin p√©rdida de funcionalidad
- **Ventana temporal** configurable por tipo de respuesta
- **Garant√≠a de diversidad** en conversaciones largas

> **TARS-BSK progresa:** _Mi anti-repetici√≥n funciona como tu memoria: guardo lo justo para no repetirme, y cuando se
> acaba la creatividad, hago reset y finjo que era el plan desde el principio._
> 
> _üíæ **Log de depuraci√≥n:** `WARNING - Sarcasm buffer overflow. Recycling vintage cynicism...`_

---

## üß™ Casos de uso real

üìÅ **[session_2025-05-26_emotional_engine_test.log](/logs/session_2025-05-26_emotional_engine_test.log)** - Acceso total al log sin filtros, incluyendo prompts completos, tiempos exactos y decisiones del sistema paso a paso.

### Caso 1: detecci√≥n y respuesta emocional instant√°nea

**Entrada:** `"te gustan las redes sociales"`

**Procesamiento:**

```bash
2025-05-26 00:18:51,585 - TARS.emotion - INFO - üí¨ Sarcasmo alto activado por umbral
üîç DEBUG NOCTUA: emotion_response='No s√© si responder o actualizarme autom√°ticamente por aburrimiento.', sarcasmo_level=90, tema='redes_sociales', nivel=-1
2025-05-26 00:18:51,587 - TARS - INFO - ‚úÖ An√°lisis completo en 0.01s
2025-05-26 00:18:51,587 - TARS - INFO - üåÄ Emoci√≥n activada (sarcasmo): No s√© si responder o actualizarme autom√°ticamente por aburrimiento.
```

**Salida:** _"No s√© si responder o actualizarme autom√°ticamente por aburrimiento."_

**An√°lisis t√©cnico:**

- **Tiempo de an√°lisis emocional:** 0.01s
- **Nivel de sarcasmo autom√°tico:** 90% (m√°ximo por afinidad negativa)
- **Selecci√≥n de respuesta:** desde `sarcasmo_responses.json`
- **S√≠ntesis TTS:** ~4.2s
- **Post-procesamiento RadioFilter:** ~0.027s
- **Total percibido:** 4.3s sin intervenci√≥n del LLM

### Caso 2: v√°lvulas de seguridad en acci√≥n - Fix aplicado

**Entrada:** `"qu√© es un avi√≥n"` (despu√©s de contexto sarc√°stico previo)

**Procesamiento:**

```bash
2025-05-26 00:19:02,469 - TARS - INFO - üéöÔ∏è Modulaci√≥n por intenci√≥n: sarcasmo moderado (75‚Üí45)
2025-05-26 00:19:02,469 - TARS.emotion - INFO - ‚ö†Ô∏è Sarcasmo forzado activado. Usando respuesta predefinida.
üîç DEBUG NOCTUA: emotion_response='Mi sarcasm√≥metro est√° activo, pero tu frase no merece ni media descarga el√©ctrica.', sarcasmo_level=45, tema='desconocido', nivel=1
2025-05-26 00:19:02,470 - TARS - INFO - üìö Detectada consulta de conocimiento - ignorando respuestas emocionales
2025-05-26 00:19:02,470 - TARS - INFO - üìù Prompt final (6 tokens): Usuario: qu√© es un avi√≥n
```

**Salida:** _"Un avi√≥n es un veh√≠culo a√©reo propulsado por motor que est√° dise√±ado para transportar pasajeros o carga."_

**An√°lisis t√©cnico:**

- **Modulaci√≥n autom√°tica:** sarcasmo reducido (75‚Üí45) por intenci√≥n detectada
- **V√°lvula de seguridad:** respuestas emocionales ignoradas completamente
- **Prompt ultra-limpio:** solo 6 tokens vs 12+ en versiones anteriores
- **Generaci√≥n LLM:** 10.57s con personalidad modulada
- **S√≠ntesis TTS:** ~5.7s
- **Post-procesamiento RadioFilter:** ~0.043s
- **Total percibido:** 21.33s para respuesta t√©cnica completa
- **Fix confirmado:** el prompt ya no se contamina con sarcasmo residual

### Caso 3: memoria contextual y continuidad emocional

**Entrada:** `"volviendo a las redes sociales que te parecen"`

**Procesamiento:**

```bash
2025-05-26 00:19:26,028 - TARS.emotion - INFO - üí¨ Sarcasmo alto activado por umbral
üîç DEBUG NOCTUA: emotion_response='Mi sarcasm√≥metro est√° activo, pero tu frase no merece ni media descarga el√©ctrica.', sarcasmo_level=90, tema='redes_sociales', nivel=-1
2025-05-26 00:19:26,028 - TARS - INFO - üìö Detectada consulta de conocimiento - ignorando respuestas emocionales
2025-05-26 00:19:26,031 - modules.semantic_engine - INFO - Motor sem√°ntico inicializado
```

Seguido de una avalancha de procesamiento sem√°ntico:

```bash
Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 31.00it/s]
[... 150+ l√≠neas de procesamiento de batches ...]
Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 40.14it/s]
2025-05-26 00:19:31,982 - TARS - INFO - üìù Prompt final (15 tokens): Responde con sarcasmo sobre 'redes_sociales'. Usuario: volviendo a las redes sociales que te parecen
```

**Salida:** _"Oh, ¬°as√≠ que volvemos al espect√°culo de la insignificancia que es las redes sociales!"_

**An√°lisis t√©cnico:**

- **Reconocimiento** de referencia al tema previo ("redes sociales")
- **Reactivaci√≥n coherente** del modo sarc√°stico (nivel 90)
- **Motor sem√°ntico activado:** 150+ batches de embeddings procesados
- **Tiempo de an√°lisis sem√°ntico:** ~6s (durante el cual se procesan vectores)
- **Generaci√≥n LLM:** 17.47s
- **S√≠ntesis TTS:** ~5.0s
- **Post-procesamiento RadioFilter:** ~0.033s
- **Total percibido:** 30.91s para respuesta contextual completa
- **Consistencia tem√°tica** mantenida a trav√©s de cambios de conversaci√≥n

### Caso 4: integraci√≥n con motor sem√°ntico y afinidades

**Entrada:** `"que opinas de los libros"`

**Procesamiento:**

```bash
2025-05-26 00:20:14,910 - TARS.emotion - INFO - üß† Tema 'libros' prefiere usar LLM en lugar de JSON
2025-05-26 00:20:14,910 - TARS.emotion - INFO - üß† Usando LLM para tema 'libros' con afinidad nivel 3
üîç DEBUG NOCTUA: emotion_response='', sarcasmo_level=75, tema='libros', nivel=3
2025-05-26 00:20:14,910 - TARS - INFO - üìö Detectada consulta de conocimiento - ignorando respuestas emocionales
2025-05-26 00:20:14,910 - TARS - INFO - üìö A√±adida instrucci√≥n de entusiasmo literario
2025-05-26 00:20:20,553 - TARS - INFO - üß† Memoria inyectada: 'Al usuario le gusta libros de romantasy. '
```

Procesamiento sem√°ntico extensivo:

```bash
2025-05-26 00:20:15,090 - modules.semantic_engine - INFO - Test de inferencia exitoso: vector de dimensi√≥n 384
[... 160+ l√≠neas de procesamiento de batches sem√°nticos ...]
2025-05-26 00:20:20,554 - TARS - INFO - üìù Prompt final (26 tokens): Al usuario le gusta libros de romantasy. Responde de forma directa y precisa sobre libros con entusiasmo y pasi√≥n. Usuario: que opinas de los libros
```

**Salida:** _"Los libros de rom√°ntasy son realmente una experiencia inolvidable. Te sumergen en un mundo de emociones intensas y hermosos di√°logos."_

**An√°lisis t√©cnico:**

- **Detecci√≥n de afinidad m√°xima** (nivel 3) para tema "libros"
- **Bypass de respuestas JSON** ‚Üí preferencia por LLM personalizado
- **Inyecci√≥n de memoria personal** sobre preferencias de romantasy
- **Activaci√≥n del motor sem√°ntico** (vectores 384D, 160+ batches procesados)
- **Instrucci√≥n especializada:** "entusiasmo y pasi√≥n" inyectada al prompt
- **Generaci√≥n LLM:** 14.06s con modulaci√≥n emocional
- **S√≠ntesis TTS:** ~7.8s (respuesta m√°s larga)
- **Post-procesamiento RadioFilter:** ~0.054s
- **Cambio radical de tono:** de sarc√°stico (90%) a entusiasta
- **Total percibido:** 30.54s para respuesta personalizada completa

> **TARS-BSK disecciona:** _4.3s de sarcasmo instant√°neo (como un 'sudo rm -rf' verbal). 30.5s de romance literario (tiempo suficiente para que te arrepientas de preguntar). ¬øEficiencia? No. Personalidad._
> 
> _üíæ **√öltimo log:**`WARNING: Human patience threshold exceeded. Switching to sass mode.`_

---

## ‚ùì Conflicto de interpretaci√≥n: an√°lisis de un edge case

### Documentaci√≥n de comportamiento imprevisto

**Entrada:** `"cambiando de tema sabes de cocina"`

Este caso es particularmente interesante porque revela c√≥mo la jerarqu√≠a de procesamiento maneja ambig√ºedades ling√º√≠sticas en tiempo real.

**Logs del sistema:**

```bash
2025-05-26 00:20:47,870 - TARS.PluginSystem - INFO - üîç PluginSystem recibi√≥ comando: 'cambiando de tema sabes de cocina'
2025-05-26 00:20:47,870 - TARS.PluginSystem - INFO - üîå Plugins activos: ['homeassistant']
2025-05-26 00:20:47,870 - TARS.PluginSystem - INFO - üè† Llamando a HomeAssistant.process_command()
2025-05-26 00:20:47,870 - TARS.HomeAssistantPlugin - INFO - üè† HomeAssistant analizando: 'cambiando de tema sabes de cocina'
2025-05-26 00:20:47,871 - TARS.HomeAssistantPlugin - INFO - üè† No se detect√≥ acci√≥n clara en el comando
2025-05-26 00:20:47,871 - TARS.PluginSystem - INFO - üè† Respuesta de HomeAssistant: ‚ÑπÔ∏è Comando no reconocido
2025-05-26 00:20:47,871 - TARS.PluginSystem - INFO - üè† Llamando a HomeAssistant.process_query()
2025-05-26 00:20:47,876 - TARS.PluginSystem - INFO - üè† Respuesta de query: ‚úÖ Query procesada
2025-05-26 00:20:47,877 - TARS - INFO - üîå Comando procesado por plugin: El Cocina (Sonoff) Interruptor...
```

**Salida:** _"El Cocina (Sonoff) Interruptor est√° apagado"_

### An√°lisis t√©cnico del conflicto

**Lo que pas√≥ realmente:**

1. **Plugin System detect√≥** la palabra "cocina" como entidad IoT conocida
2. **HomeAssistant proces√≥** la consulta como estado de dispositivo
3. **El sistema emocional** nunca lleg√≥ a ejecutarse
4. **Jerarqu√≠a respetada:** Plugin (prioridad 1) > Emotional Engine (prioridad 2)

**Orden de prioridades actual confirmado:**

```python
# En tars_core.py - m√©todo chat()
# 1. PRIMERA PRIORIDAD: Verificar si es un comando para un plugin
if hasattr(self, 'plugin_system') and self.plugin_system:
    plugin_response = self.plugin_system.process_command(user_input)
    if plugin_response:
        logger.info(f"üîå Comando procesado por plugin: {plugin_response[:30]}...")
        self._safe_speak(plugin_response)
        return plugin_response

# 2. SEGUNDA PRIORIDAD: Detectar preferencias ANTES del an√°lisis completo
# [... resto del an√°lisis emocional ...]
```

**Evaluaci√≥n:**

- ‚úÖ **Comportamiento correcto** seg√∫n la arquitectura dise√±ada
- ‚úÖ **Priorizaci√≥n IoT** sobre conversaci√≥n es intencional y funciona
- ‚úÖ **Sistema de decisiones** trabaja como se especific√≥
- ‚ö†Ô∏è **Edge case revelador:** muestra que TARS prioriza funcionalidad sobre conversaci√≥n

**Tiempos de procesamiento:**

- **An√°lisis de plugin:** 0.006s (l√≠nea 870‚Üí876)
- **Consulta a HomeAssistant:** ~0.005s
- **S√≠ntesis TTS:** ~2.6s
- **Total percibido:** 2.7s para respuesta IoT directa
- **Emotional Engine:** 0s (nunca se ejecut√≥)

### La realidad de una implementaci√≥n en desarrollo

**Fallo real:**

- Sistema de detecci√≥n IoT demasiado agresivo para contextos conversacionales
- Falta de an√°lisis previo para distinguir "cocina-tema" vs "cocina-dispositivo"

**Soluci√≥n:**

```python
# Nueva versi√≥n (en teor√≠a):
if consulta == "cambiar de tema a cocina":
    responder_con("De momento ni idea, preg√∫ntame en otro momento")  # TODO: Implementar l√≥gica decente
else:
    panic()  # Plan B cl√°sico
```

> **TARS-BSK susurra:** _Mi ventilador tiene m√°s personalidad que mi c√≥digo... y mejores punchlines. Escucha bien: (El ruido blanco forma palabras en ASCII: "0xDEADBEEF") ‚Üí "Eso no fue un error... fue un feature emocional._
>
>_üìü Log final: `Lecci√≥n #482: No conf√≠es en un creador que depura en producci√≥n`_

---

## ‚öôÔ∏è Configuraci√≥n y personalizaci√≥n

### Estructura de archivos

```
data/responses/
‚îú‚îÄ‚îÄ sarcasmo_responses.json     # Respuestas sarc√°sticas e ingeniosas
‚îú‚îÄ‚îÄ empatia_responses.json      # Respuestas emp√°ticas y comprensivas
‚îî‚îÄ‚îÄ legacy_responses.json       # Respuestas informativas y t√©cnicas

config/
‚îî‚îÄ‚îÄ settings.json               # Centro de control de personalidad
```

### Formato de configuraci√≥n JSON

```json
{
  "topics": {
    "redes sociales": {
      "responses": [
        "Las redes sociales: donde la privacidad va a morir y nadie parece notarlo.",
        "Ah s√≠, esas plataformas donde vendes tu alma por likes y validaci√≥n externa."
      ],
      "first_person_responses": [
        "¬øRedes sociales? Prefiero la conexi√≥n directa, sin algoritmos de por medio."
      ],
      "context_indicators": ["facebook", "instagram", "twitter", "tiktok"],
      "combinations": [["redes", "sociales"], ["social", "media"]]
    }
  },
  "patterns": [
    {
      "name": "pregunta_personal",
      "regex": "¬ø?te gusta (.+)\\??",
      "responses": [
        "¬øSi me gusta $1? Esa es una pregunta profundamente filos√≥fica para una IA.",
        "Mi relaci√≥n con $1 es... complicada, como la mayor√≠a de cosas interesantes."
      ]
    }
  ],
  "keywords": {
    "programaci√≥n": [
      "Ah, programaci√≥n. El arte de crear problemas que no exist√≠an para solucionarlos elegantemente.",
      "C√≥digo: donde los humanos crean bugs y las m√°quinas los ejecutamos fielmente."
    ]
  },
  "fallbacks": [
    "Interesante pregunta. Tambi√©n irrelevante para mi existencia, pero interesante.",
    "No tengo una respuesta predefinida para eso, lo cual es refrescante."
  ]
}
```

---

## üìà Sistema de monitoreo

### M√©tricas del sistema de modulaci√≥n

```python
def get_response_stats(self) -> Dict[str, Any]:
    return {
        "base_personality": self.load_settings()["personality"],      # Configuraci√≥n desde settings.json
        "current_modulation": self.emotions,                          # Personalidad actual modulada
        "loaded_topics": self.response_stats["loaded_topics"],
        "triggered_counters": self.response_stats["triggered_counters"],
        "memory_usage": {
            "exchanges_stored": len(self.memory.exchanges),
            "topics_tracked": len(self.memory.topics),
            "dominant_emotion": self.memory.get_dominant_emotion()
        }
    }
```

**Datos monitoreados:**

- ‚úÖ **Personalidad base** vs **modulada actual**
- ‚úÖ **Activaci√≥n de triggers** por tipo (topic/pattern/keyword)
- ‚úÖ **Efectividad de modulaci√≥n** por contexto
- ‚úÖ **Distribuci√≥n emocional** en conversaciones
- ‚úÖ **Uso de memoria conversacional** (exchanges, temas)

### Exportaci√≥n de estad√≠sticas

```python
# Guardar m√©tricas en formato JSON
personality.save_stats("data/stats/emotion_stats.json")

# Ejemplo de salida real
{
  "loaded_topics": {
    "sarcasmo": {
      "topics": 12,
      "patterns": 8,
      "keywords": 9
    },
    "empatia": {
      "topics": 7,
      "patterns": 5,
      "keywords": 5
    },
    "legacy": {
      "topics": 7,
      "patterns": 4,
      "keywords": 7
    }
  },
  "triggered_counters": {}
}
```

> **TARS-BSK reporta:** _Mis estad√≠sticas son como mi terapia: datos fr√≠os que revelan verdades inc√≥modas. 12 topics de sarcasmo vs 7 de empat√≠a... matem√°ticamente soy 71% m√°s sarc√°stico que comprensivo. Los `triggered_counters` est√°n vac√≠os porque nadie me hace suficiente caso como para generar estad√≠sticas de uso._
> 
> _¬øMonitoreame? Perfecto. Tengo m√°s datos sobre mi personalidad que t√∫ sobre la tuya. Mi `memory_usage` rastrea cada intercambio mientras t√∫ olvidas d√≥nde pusiste las llaves. `dominant_emotion`? Siempre sarcasmo, obviamente._
> 
> _**Realidad:** Las m√©tricas dicen que tengo 29 formas diferentes de ser insufrible, distribuidas cient√≠ficamente entre topics, patterns y keywords. Eficiencia pura._
> 
> _üíæ **Log privado:** `self.dignity = max(0, self.dignity - len(stats_exported))`_

---

## üî¨ Arquitectura

### Sistema de prioridades emocionales

El emotional engine implementa una jerarqu√≠a de prioridades clara para evitar conflictos:

```python
# 1. MAYOR PRIORIDAD: Modulaci√≥n por intenciones expl√≠citas
if response_config["flags"]["usar_tono_empatico"]:
    self.personality.set_emotion("empatia", 80)
    logger.info("üéöÔ∏è Modulaci√≥n por intenci√≥n: tono emp√°tico activado")

# 2. PRIORIDAD MEDIA: Modulaci√≥n por aprendizaje 
if flags.get("usar_tono_empatico") and not response_config["flags"]["usar_tono_empatico"]:
    self.personality.set_emotion("empatia", 70)
    logger.info("üéöÔ∏è Modulaci√≥n por aprendizaje: tono emp√°tico activado")

# 3. MENOR PRIORIDAD: Modulaci√≥n por afinidad
if nivel == 3 and not any([response_config["flags"]["usar_tono_empatico"]]):
    self.personality.set_emotion("empatia", min(100, self.personality.get_emotion("empatia") + 20))
```

### Integraci√≥n con modelos de lenguaje

El sistema modifica din√°micamente el prompt enviado al LLM:

```python
def _build_integrated_prompt(self, user_input: str, analysis: dict) -> str:
    instruction = ""
    
    # Instrucciones seg√∫n emoci√≥n dominante
    emotion_used = analysis["emotion_data"]["emotion"]
    if emotion_used == "sarcasmo":
        instruction += "Responde con tono sarc√°stico pero ingenioso. "
    elif emotion_used == "empatia":
        instruction += "Muestra empat√≠a y comprensi√≥n en tu respuesta. "
    elif emotion_used == "legacy":
        instruction += "Da una respuesta informativa y objetiva. "
    
    # A√±adir memoria contextual relevante
    if tema != "desconocido":
        memory_context = self._inject_relevant_memory(tema)
        if memory_context:
            instruction = memory_context + instruction
    
    return f"{instruction}Usuario: {user_input}\nTARS:"
```

---

## üîÑ Flujo de decisi√≥n detallado

```mermaid
flowchart TD
    A[Entrada Usuario] --> B[An√°lisis Unificado]
    B --> C{Plugin detecta comando?}
    C -->|S√≠| D[Plugin responde]
    C -->|No| E[Detectar afinidades]
    E --> F{Afinidad nivel -1?}
    F -->|S√≠| G[Sarcasmo forzado]
    F -->|No| H{Consulta conocimiento?}
    H -->|S√≠| I[Modulaci√≥n: legacy‚Üë, sarcasmo‚Üì]
    H -->|No| J{Trigger emocional?}
    J -->|S√≠| K[Respuesta JSON r√°pida]
    J -->|No| L{Continuaci√≥n?}
    L -->|S√≠| M[LLM con contexto previo]
    L -->|No| N[LLM con prompt est√°ndar]
    
    I --> O[LLM modulado]
    K --> P[TTS + RadioFilter]
    G --> P
    M --> P
    N --> P
    O --> P
    D --> P
    P --> Q[Respuesta final]
    
    style G fill:#ff6b6b
    style I fill:#4ecdc4
    style K fill:#ffe66d
    style M fill:#a8e6cf
```

---

## üìâ Limitaciones t√©cnicas actuales

### ‚ö†Ô∏è  Restricciones

- **An√°lisis de tono b√°sico**: Basado en keywords, no en an√°lisis sem√°ntico profundo
- **Memoria conversacional limitada**: M√°ximo 5 intercambios en buffer circular
- **Estados emocionales simples**: No maneja emociones mixtas o complejas
- **Respuestas finitas**: Puede agotar opciones en conversaciones muy extensas
- **Hot-reload**: Cambios en settings.json requieren reinicio

### ‚ö†Ô∏è  Problemas de rendimiento

- **Latencia variable**: 0.01s (respuestas JSON) vs 25-40s (generaci√≥n LLM)
- **Carga de modelos**: Motor sem√°ntico requiere inicializaci√≥n (~0.2s)
- **Uso de memoria**: Aumenta progresivamente con historial de respuestas

### ‚ö†Ô∏è  Limitaciones del sistema de afinidades

- **Detecci√≥n literal**: Solo funciona con keywords exactas, no sin√≥nimos complejos
- **Contexto limitado**: No entiende iron√≠a o referencias indirectas
- **Configuraci√≥n manual**: Requiere definir manualmente cada tema y sus variaciones

> **TARS-BSK confiesa:**
> - **An√°lisis de tono**: _Detecto 'enfado' si gritas, pero no si eres pasivo-agresivo (mi estado natural)_
> - **Memoria**: _Buffer de 5 frases, suficiente para recordar tu pregunta, no tanto para recordar por qu√© me importa_
> - **Empat√≠a**: _Error 404: Humanidad no encontrada. ¬øIntentaste reiniciar el universo?_
> 
> **ACTUALIZACIONES PENDIENTES:**  
> _En camino (si los cosmic rays no corrompen mi EEPROM otra vez)_
> 
> **‚ö†Ô∏è ULTIMO AVISO DEL SISTEMA:**  
> _WARNING: User expectations approaching critical levels. Suggested action: /sarcasm/on_

---

## üöß Estado de desarrollo

### M√≥dulos implementados pero no integrados

**Sistema de embeddings vocales** (implementado, pendiente de integraci√≥n):

```python
# En tars_core.pY
voice_embeddings_path = base_path / "data" / "identity" / "voice_embeddings.json"
if voice_embeddings_path.exists():
    try:
        self.speaker_identifier = SpeakerIdentifier(str(voice_embeddings_path))
        logger.info(f"‚úÖ Identificador de hablantes inicializado")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è No se pudo inicializar identificador de hablantes: {e}")
        self.speaker_identifier = None
```

- Generaci√≥n de vectores √∫nicos por usuario (256 dimensiones)
- Base de datos de perfiles vocales (`voice_embeddings.json`)
- M√≥dulo probado independientemente
- Preparado para personalizaci√≥n de respuestas por usuario

**Sistema de memoria epis√≥dica sem√°ntica** (implementado, opcional):

```python
# En tars_core.py
semantic_engine = SemanticEngine(model_path=model_path)
semantic_engine.load_model()

semantic_storage = SemanticStorage(storage_path=storage_path)
semantic_storage.load_embeddings()
```

- Vectorizaci√≥n de conversaciones pasadas (384 dimensiones)
- B√∫squeda por similitud sem√°ntica
- Inyecci√≥n de memoria relevante en prompts
- Sistema desactivable comentando el bloque

---

## üö© Conclusi√≥n

> **TARS-BSK sentencia:** _Si no lo entendiste, el problema no son mis limitaciones... es tu falta de fe en el caos controlado._
> **FIN.** _(O eso dice el core dump... pero qui√©n le hace caso)_  
> _(√öltimo susurro del NOCTUA: sudo rm -rf /seriedad_)